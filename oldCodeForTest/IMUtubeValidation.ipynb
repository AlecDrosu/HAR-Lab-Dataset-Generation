{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from io import StringIO\n",
    "from sklearn.model_selection import KFold\n",
    "from oldslidingWindow import read_data, segment_data_by_day, sliding_window\n",
    "\n",
    "REAL_DATA = '../Processed Data/Aruba_17/processed_data.csv'\n",
    "FAKE_DATA = '../Predictions/Aruba_17_prediction_419.txt'\n",
    "\n",
    "# Read the data as a string and split it by lines\n",
    "with open(REAL_DATA, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "lines = lines[1:]\n",
    "data_str = '\\n'.join(lines)\n",
    "data_df = pd.read_csv(StringIO(data_str), delimiter=',', header=None, dtype=float)\n",
    "data_df = data_df.iloc[:10000, :]\n",
    "\n",
    "# Read the data as a string and split it by lines\n",
    "with open(FAKE_DATA, 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "fake_data_str = '\\n'.join(lines)\n",
    "fake_data_df = pd.read_csv(StringIO(fake_data_str), delimiter=',', header=None, dtype=float)\n",
    "fake_data_df = fake_data_df.iloc[:10000, :]\n",
    "\n",
    "daily_segments_real = segment_data_by_day(data_df)\n",
    "daily_segments_fake = segment_data_by_day(fake_data_df)\n",
    "window_size = 7816\n",
    "overlap_ratio = 0.2\n",
    "windows_real = sliding_window(daily_segments_real, window_size=window_size, overlap_ratio=overlap_ratio)\n",
    "windows_fake = sliding_window(daily_segments_fake, window_size=window_size, overlap_ratio=overlap_ratio)\n",
    "\n",
    "data = data_df.iloc[:, :6].to_numpy()\n",
    "labels = data_df.iloc[:, 4:].astype(str).apply(lambda x: '_'.join(x), axis=1).to_numpy()\n",
    "fake_data = fake_data_df.iloc[:, :6].to_numpy()\n",
    "fake_labels = fake_data_df.iloc[:, 4:].astype(str).apply(lambda x: '_'.join(x), axis=1).to_numpy()\n",
    "\n",
    "\n",
    "def evaluate_classifier(data, labels):\n",
    "    loo = LeaveOneOut()\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    all_reports = []\n",
    "    balanced_accuracies = []\n",
    "\n",
    "    for train_index, test_index in loo.split(data):\n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = encoded_labels[train_index], encoded_labels[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier(n_jobs=-1, n_estimators=50, min_samples_leaf=20)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "        bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        report = {\"weighted_precision\": weighted_precision, \"weighted_recall\": weighted_recall, \"weighted_fscore\": weighted_fscore}\n",
    "        all_reports.append(report)\n",
    "        balanced_accuracies.append(bal_acc)\n",
    "\n",
    "    mean_report = pd.DataFrame(all_reports).mean()\n",
    "    mean_balanced_accuracy = np.mean(balanced_accuracies)\n",
    "\n",
    "    return mean_report, mean_balanced_accuracy\n",
    "\n",
    "# def evaluate_classifier(data, labels):\n",
    "#     kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#     label_encoder = LabelEncoder()\n",
    "#     encoded_labels = label_encoder.fit_transform(labels)\n",
    "    \n",
    "#     all_reports = []\n",
    "#     balanced_accuracies = []\n",
    "\n",
    "#     for train_index, test_index in kf.split(data):\n",
    "#         X_train, X_test = data[train_index], data[test_index]\n",
    "#         y_train, y_test = encoded_labels[train_index], encoded_labels[test_index]\n",
    "\n",
    "#         clf = RandomForestClassifier(n_jobs=-1, n_estimators=50)\n",
    "#         clf.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred = clf.predict(X_test)\n",
    "#         weighted_precision, weighted_recall, weighted_fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "#         bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "#         report = {\"weighted_precision\": weighted_precision, \"weighted_recall\": weighted_recall, \"weighted_fscore\": weighted_fscore}\n",
    "#         all_reports.append(report)\n",
    "#         balanced_accuracies.append(bal_acc)\n",
    "\n",
    "#     mean_report = pd.DataFrame(all_reports).mean()\n",
    "#     mean_balanced_accuracy = np.mean(balanced_accuracies)\n",
    "\n",
    "#     return mean_report, mean_balanced_accuracy\n",
    "\n",
    "# Prepare your data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Call the evaluation function for both datasets\n",
    "mean_report_original, mean_balanced_accuracy_original = evaluate_classifier(data, labels)\n",
    "mean_report_fake, mean_balanced_accuracy_fake = evaluate_classifier(fake_data, fake_labels)\n",
    "\n",
    "# Print the evaluation metrics for both datasets\n",
    "print(\"Original dataset:\")\n",
    "print(f\"Balanced accuracy: {mean_balanced_accuracy_original:.2f}\")\n",
    "print(f\"Weighted precision: {mean_report_original['weighted_precision']:.2f}\")\n",
    "print(f\"Weighted recall: {mean_report_original['weighted_recall']:.2f}\")\n",
    "print(f\"Weighted F-score: {mean_report_original['weighted_fscore']:.2f}\")\n",
    "\n",
    "print(\"\\nFake dataset:\")\n",
    "print(f\"Balanced accuracy: {mean_balanced_accuracy_fake:.2f}\")\n",
    "print(f\"Weighted precision: {mean_report_fake['weighted_precision']:.2f}\")\n",
    "print(f\"Weighted recall: {mean_report_fake['weighted_recall']:.2f}\")\n",
    "print(f\"Weighted F-score: {mean_report_fake['weighted_fscore']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
