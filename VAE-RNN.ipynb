{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alec\\AppData\\Local\\Temp\\ipykernel_42644\\1084665593.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  windows = np.asarray([window.to_numpy() for window in windows])\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, TimeDistributed, Reshape, Bidirectional, Masking\n",
    "from keras.models import Model \n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sliding_window import read_data, segment_data_by_day, sliding_window\n",
    "# from custom_penalty import custom_penalty\n",
    "from custom_layers import CustomPenaltyLayer\n",
    "FILE_PATH = 'Processed Data/Aruba_17/processed_data.csv'\n",
    "\n",
    "data_df = read_data(FILE_PATH)\n",
    "daily_segments = segment_data_by_day(data_df)\n",
    "daily_segments = daily_segments[:10]\n",
    "windows = sliding_window(daily_segments)\n",
    "\n",
    "# Prepare the data\n",
    "windows = np.asarray([window.to_numpy() for window in windows])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "timesteps = max([window.shape[0] for window in windows])\n",
    "input_dim = windows[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 68s 68s/step - loss: 42220.6992 - val_loss: 59930.7461\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 30s 30s/step - loss: 42179.5391 - val_loss: 59766.8398\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 31s 31s/step - loss: 41919.9609 - val_loss: 59510.6875\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 29s 29s/step - loss: 41613.5391 - val_loss: 59235.3672\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 29s 29s/step - loss: 41349.6250 - val_loss: 59061.2109\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 6653, 8395, 5849, 8491, 6240, 9884, 5444, 6655\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alec\\Desktop\\Code\\HAR Research\\Virtual Data\\VAE-RNN.ipynb Cell 2\u001b[0m in \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W1sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m# Use the encoder to generate embeddings for each sequence\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m encoder_model \u001b[39m=\u001b[39m Model(inputs, z_mean)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W1sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m X_embedded \u001b[39m=\u001b[39m encoder_model\u001b[39m.\u001b[39;49mpredict(window_train, batch_size\u001b[39m=\u001b[39;49mbatch_size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\data_adapter.py:1848\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1842\u001b[0m         label,\n\u001b[0;32m   1843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1844\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1845\u001b[0m         ),\n\u001b[0;32m   1846\u001b[0m     )\n\u001b[0;32m   1847\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1848\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 6653, 8395, 5849, 8491, 6240, 9884, 5444, 6655\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# Create a new train-test split using the windows\n",
    "window_train, window_val = train_test_split(list(windows), test_size=validation_split, shuffle=False)\n",
    "\n",
    "# Normalize the data using minMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "window_train = [scaler.fit_transform(window) for window in window_train]\n",
    "window_val = [scaler.transform(window) for window in window_val]\n",
    "\n",
    "max_length = max([window.shape[0] for window in windows])\n",
    "window_train_padded = pad_sequences(window_train, maxlen=max_length, dtype='float32', padding='post', value=-1)\n",
    "window_val_padded = pad_sequences(window_val, maxlen=max_length, dtype='float32', padding='post', value=-1)\n",
    "\n",
    "# Create tf.data.Dataset from the padded sequences\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(window_train_padded).batch(batch_size)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(window_val_padded).batch(batch_size)\n",
    "\n",
    "latent_dim = 2\n",
    "encoding_dim = 32\n",
    "\n",
    "# ==================== ENCODER ====================\n",
    "inputs = Input(shape=(max_length, input_dim), name='encoder_input')\n",
    "mask = Masking(mask_value=-1.0)(inputs)  # Add masking layer\n",
    "x = Bidirectional(LSTM(encoding_dim * 2, return_sequences=True))(mask)\n",
    "x = Bidirectional(LSTM(encoding_dim, return_sequences=False))(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "# z_mean is the mean of the latent space\n",
    "# z_log_var is the variance of the latent space\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# ================= LATENT SPACE ==================\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "# ==================== DECODER ====================\n",
    "x = Dense(timesteps * encoding_dim, activation='relu')(latent_inputs)\n",
    "x = Reshape((timesteps, encoding_dim))(x)\n",
    "x = Bidirectional(LSTM(encoding_dim, return_sequences=True, input_shape=(timesteps, encoding_dim)))(x)\n",
    "x = TimeDistributed(Dense(input_dim))(x)\n",
    "# LSTM layer in the decoder is used to reconstruct the original sequence\n",
    "\n",
    "# the VAE model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(latent_inputs, x, name='decoder')\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "# VAE loss function with custom_penalty\n",
    "# reconstruction_loss = binary_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss = K.mean(K.square(inputs - outputs))\n",
    "reconstruction_loss *= timesteps * input_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "# Add the custom penalty to the loss function\n",
    "penalty_weight = 10.0  # Adjust the weight of the penalty term as needed\n",
    "penalty_layer = CustomPenaltyLayer(scaler, input_dim)\n",
    "penalty = penalty_layer(outputs)\n",
    "penalty *= penalty_weight\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss + penalty)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "num_epochs = 5\n",
    "history = vae.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n",
    "\n",
    "# Use the encoder to generate embeddings for each sequence\n",
    "encoder_model = Model(inputs, z_mean)\n",
    "\n",
    "# Use the encoder to generate embeddings for each sequence\n",
    "encoder_model = Model(inputs, z_mean)\n",
    "X_embedded = encoder_model.predict(window_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fake dataset using the VAE model\n",
    "n_samples = len(windows)\n",
    "\n",
    "# Sample from the latent space\n",
    "z_samples = np.random.normal(size=(n_samples, latent_dim))\n",
    "\n",
    "# Use the decoder to generate the output\n",
    "predicted_values = decoder.predict(z_samples)\n",
    "predicted_values = np.reshape(predicted_values, (n_samples, timesteps, input_dim))\n",
    "\n",
    "# Undo the normalization\n",
    "predicted_values = np.reshape(predicted_values, (-1, input_dim))\n",
    "predicted_values = scaler.inverse_transform(predicted_values)\n",
    "\n",
    "# Round each of the values in the array to the nearest integer\n",
    "predicted_values = np.rint(predicted_values)\n",
    "\n",
    "# Create the fake dataset in the original format\n",
    "fake_dataset = []\n",
    "for window in predicted_values.reshape((n_samples, timesteps, input_dim)):\n",
    "    fake_dataset.extend(window)\n",
    "\n",
    "# Save the fake dataset to a new file 'fake_dataset.txt'\n",
    "fake_data = pd.DataFrame(fake_dataset, columns=['Date', 'Time', 'Device ID', 'Status', 'Activity', 'Activity Status'])\n",
    "\n",
    "with open('Aruba_17_prediction.txt', 'w') as file:\n",
    "    for _, row in fake_data.iterrows():\n",
    "        file.write(','.join(map(str, row.values)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss with x and y labels, and a grid\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Validation loss > training loss, underfitting\n",
    "# validation loss > training loss, overfitting, if it decreases and then increases again.\n",
    "# If they both decreease and stabilize at a specific point, it is an optimal fit.\n",
    "\n",
    "# Plot the evaluation loss vs the iterations\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the model\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# # Display the layers, number of layers, number of nodes etc\n",
    "# plot_model(vae, to_file='vae.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# # Load the image and display it\n",
    "# img = plt.imread('vae.png')\n",
    "# plt.figure(figsize=(16, 12))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
