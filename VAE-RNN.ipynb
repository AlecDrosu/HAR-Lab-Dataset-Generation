{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, RepeatVector, TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "# from custom_penalty import custom_penalty\n",
    "\n",
    "# Load the original dataset\n",
    "processed_data = pd.read_csv('Processed Data/Aruba_17/processed_data.csv')\n",
    "# Find the maximum number that can be evenly divisible by 32, given the length of the dataset\n",
    "max_length = len(processed_data) - len(processed_data) % 32\n",
    "# processed_data = processed_data.head(16000)\n",
    "# only use all the rows up to the max_length\n",
    "processed_data = processed_data.head(3200)\n",
    "# Extract the relevant columns from the dataset\n",
    "timestamp = processed_data['Timestamp'].values\n",
    "device_id = processed_data['Device ID'].values\n",
    "status = processed_data['Status'].values\n",
    "activity = processed_data['Activity'].values\n",
    "activity_status = processed_data['Activity Status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.stack((timestamp, device_id, status, activity, activity_status), axis=1)\n",
    "\n",
    "# # Normalize the data using z-score normalization\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Scale the values to be within the range of 0 to 1\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1' defined at (most recent call last):\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Temp\\ipykernel_9512\\1569361181.py\", line 129, in <module>\n      history = vae.fit(X_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1'\nIncompatible shapes: [20480] vs. [7680]\n\t [[{{node gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1}}]] [Op:__inference_train_function_134965]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alec\\Desktop\\Code\\HAR Research\\Virtual Data\\VAE-RNN.ipynb Cell 3\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m \u001b[39m# vae.summary()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m \u001b[39m# callbacks=[tensorboard_callback]\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m history \u001b[39m=\u001b[39m vae\u001b[39m.\u001b[39;49mfit(X_train, epochs\u001b[39m=\u001b[39;49mnum_epochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39m# plot_model(vae, to_file='model.png', show_shapes=True)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39m# Use the encoder to generate embeddings for each sequence\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alec/Desktop/Code/HAR%20Research/Virtual%20Data/VAE-RNN.ipynb#W2sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m encoder_model \u001b[39m=\u001b[39m Model(inputs, z_mean)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1' defined at (most recent call last):\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\traitlets\\config\\application.py\", line 982, in launch_instance\n      app.start()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Temp\\ipykernel_9512\\1569361181.py\", line 129, in <module>\n      history = vae.fit(X_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"C:\\Users\\Alec\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1'\nIncompatible shapes: [20480] vs. [7680]\n\t [[{{node gradient_tape/vae/tf.keras.backend.binary_crossentropy_7/mul_1/Mul_1}}]] [Op:__inference_train_function_134965]"
     ]
    }
   ],
   "source": [
    "# Define the log directory for TensorBoard\n",
    "# log_dir = \"logs/\"\n",
    "\n",
    "# Create a callback for TensorBoard\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Prepare the data for input into the VAE model\n",
    "X = np.stack((timestamp, device_id, status, activity, activity_status), axis=1)\n",
    "\n",
    "# Normalize the data using minMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# print(X.head(20))\n",
    "# Find the corresponding normalized values\n",
    "temp_min_max_values = np.zeros((4, 5))\n",
    "temp_min_max_values[0, 0] = 0\n",
    "temp_min_max_values[1, 0] = processed_data['Timestamp'].nunique() - 1\n",
    "\n",
    "# M sensors\n",
    "temp_min_max_values[0, 1] = 3\n",
    "temp_min_max_values[1, 1] = 33\n",
    "temp_min_max_values[0, 2] = 54\n",
    "temp_min_max_values[1, 2] = 55  # 'OFF' and 'ON' status values for M sensors\n",
    "\n",
    "# T sensors\n",
    "temp_min_max_values[2, 1] = 34\n",
    "temp_min_max_values[3, 1] = 38\n",
    "temp_min_max_values[2, 2] = 0\n",
    "temp_min_max_values[3, 2] = 43  # Temperature values for T sensors\n",
    "\n",
    "# D sensors\n",
    "temp_min_max_values[0, 1] = 0\n",
    "temp_min_max_values[1, 1] = 2\n",
    "temp_min_max_values[0, 2] = 53\n",
    "temp_min_max_values[1, 2] = 56  # 'CLOSE' and 'OPEN' status values for D sensors\n",
    "\n",
    "temp_min_max_values[:, 4] = [0, 2, 0, 2]     # Activity Status values\n",
    "\n",
    "# Find the corresponding normalized values using the scaler\n",
    "normalized_min_max_values = scaler.transform(temp_min_max_values)\n",
    "\n",
    "# Use KMeans to cluster sequences into 14 different groups\n",
    "# kmeans = KMeans(n_clusters=14, random_state=0)\n",
    "# clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "timesteps = 128 # number of previous records considered\n",
    "input_dim = X.shape[1] # number of features, there are 5 features in the dataset\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, X, test_size=validation_split, shuffle=False)\n",
    "\n",
    "# Pad the data to ensure it is divisible by the desired shape\n",
    "remainder_train = X_train.shape[0] % (batch_size * timesteps)\n",
    "if remainder_train > 0:\n",
    "    X_train = np.concatenate([X_train[:-remainder_train], np.zeros((batch_size * timesteps - remainder_train, input_dim))])\n",
    "    y_train = np.concatenate([y_train[:-remainder_train], np.zeros((batch_size * timesteps - remainder_train, input_dim))])\n",
    "\n",
    "remainder_val = X_val.shape[0] % (batch_size * timesteps)\n",
    "if remainder_val > 0:\n",
    "    X_val = np.concatenate([X_val[:-remainder_val], np.zeros((batch_size * timesteps - remainder_val, input_dim))])\n",
    "    y_val = np.concatenate([y_val[:-remainder_val], np.zeros((batch_size * timesteps - remainder_val, input_dim))])\n",
    "\n",
    "# Reshape the datasets to have the correct shape for the model\n",
    "X_train = X_train.reshape((-1, timesteps, input_dim))\n",
    "y_train = y_train.reshape((-1, timesteps, input_dim))\n",
    "\n",
    "X_val = X_val.reshape((-1, timesteps, input_dim))\n",
    "y_val = y_val.reshape((-1, timesteps, input_dim))\n",
    "\n",
    "latent_dim = 2\n",
    "encoding_dim = 32\n",
    "\n",
    "# ==================== ENCODER ====================\n",
    "inputs = Input(batch_shape=(batch_size, timesteps, input_dim), name='encoder_input')\n",
    "x = LSTM(encoding_dim*2, return_sequences=True)(inputs)\n",
    "x = LSTM(encoding_dim, return_sequences=False)(x) \n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "# z_mean is the mean of the latent space\n",
    "# z_log_var is the variance of the latent space\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "# encoder.summary()\n",
    "\n",
    "# ================= LATENT SPACE ==================\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "# ==================== DECODER ====================\n",
    "x = Dense(timesteps * encoding_dim, activation='relu')(latent_inputs)\n",
    "x = Reshape((timesteps, encoding_dim))(x)\n",
    "x = LSTM(encoding_dim, return_sequences=True, input_shape=(timesteps, encoding_dim))(x)\n",
    "x = TimeDistributed(Dense(input_dim))(x)\n",
    "# LSTM layer in the decoder is used to reconstruct the original sequence\n",
    "\n",
    "# the VAE model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(latent_inputs, x, name='decoder')\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "def custom_penalty(y_pred, normalized_min_max_values, input_dim):\n",
    "    y_pred = K.reshape(y_pred, (-1, input_dim))\n",
    "\n",
    "    y_pred_device_id = y_pred[:, 1]\n",
    "    y_pred_status = y_pred[:, 2]\n",
    "\n",
    "    penalties = []\n",
    "    for i in range(3):\n",
    "        min_device_id = K.reshape(normalized_min_max_values[i * 2, 1], K.shape(y_pred_device_id))\n",
    "        max_device_id = K.reshape(normalized_min_max_values[i * 2 + 1, 1], K.shape(y_pred_device_id))\n",
    "        min_status = K.reshape(normalized_min_max_values[i * 2, 2], K.shape(y_pred_status))\n",
    "        max_status = K.reshape(normalized_min_max_values[i * 2 + 1, 2], K.shape(y_pred_status))\n",
    "\n",
    "        device_penalty = K.sum(K.relu(y_pred_device_id - max_device_id) + K.relu(min_device_id - y_pred_device_id))\n",
    "        status_penalty = K.sum(K.relu(y_pred_status - max_status) + K.relu(min_status - y_pred_status))\n",
    "\n",
    "        penalties.append(device_penalty + status_penalty)\n",
    "\n",
    "    penalty = K.mean(K.stack(penalties, axis=0))\n",
    "\n",
    "    return penalty\n",
    "\n",
    "# Loss function\n",
    "reconstruction_loss = binary_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss *= timesteps * input_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "\n",
    "# Add the custom penalty to the loss function\n",
    "penalty_weight = 10.0  # Adjust the weight of the penalty term as needed\n",
    "# penalty = custom_penalty(y_pred=outputs)\n",
    "penalty = custom_penalty(outputs, normalized_min_max_values, input_dim)\n",
    "penalty *= penalty_weight\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss + penalty)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "# vae.summary()\n",
    "# callbacks=[tensorboard_callback]\n",
    "num_epochs = 300\n",
    "history = vae.fit(X_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "\n",
    "# plot_model(vae, to_file='model.png', show_shapes=True)\n",
    "# Use the encoder to generate embeddings for each sequence\n",
    "encoder_model = Model(inputs, z_mean)\n",
    "# print(encoder_model.layers[0].input_shape)\n",
    "\n",
    "X_embedded = encoder_model.predict(X_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "100/100 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate a fake dataset using the VAE model\n",
    "n_samples = len(processed_data)\n",
    "\n",
    "# Sample from the latent space\n",
    "z_samples = np.random.normal(size=(n_samples, latent_dim))\n",
    "\n",
    "# Use the decoder to generate the output\n",
    "predicted_values = decoder.predict(z_samples)\n",
    "predicted_values = np.reshape(predicted_values, (n_samples, timesteps, input_dim))\n",
    "\n",
    "# Undo the normalization\n",
    "predicted_values = np.reshape(predicted_values, (-1, input_dim))\n",
    "predicted_values = scaler.inverse_transform(predicted_values)\n",
    "\n",
    "# Round each of the values in the array to the nearest integer\n",
    "predicted_values = np.rint(predicted_values)\n",
    "\n",
    "# Save the prediction data to a new file 'predicted_Data.csv'\n",
    "predicted_data = pd.DataFrame(predicted_values.reshape((-1, input_dim)), columns=['Timestamp', 'Device ID', 'Status', 'Activity', 'Activity Status'])\n",
    "\n",
    "with open('Predictions/Aruba_17_prediction.txt', 'w') as file:\n",
    "    for _, row in predicted_data.iterrows():\n",
    "        file.write(','.join(map(str, row.values)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss with x and y labels, and a grid\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Validation loss > training loss, underfitting\n",
    "# validation loss > training loss, overfitting, if it decreases and then increases again.\n",
    "# If they both decreease and stabilize at a specific point, it is an optimal fit.\n",
    "\n",
    "# Plot the evaluation loss vs the iterations\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the model\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# # Display the layers, number of layers, number of nodes etc\n",
    "# plot_model(vae, to_file='vae.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# # Load the image and display it\n",
    "# img = plt.imread('vae.png')\n",
    "# plt.figure(figsize=(16, 12))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
