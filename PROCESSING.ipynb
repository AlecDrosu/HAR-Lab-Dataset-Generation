{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing code\n",
    "This code will convert the original data file into a csv for the Aruba dataset. Saved as pre_processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file for reading\n",
    "with open(\"Raw Data/Aruba_17/data\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data = []\n",
    "\n",
    "# Possible activities\n",
    "activities = [\"Meal_Preparation\", \"Relax\", \"Eating\", \"Work\", \"Sleeping\", \"Wash_Dishes\", \"Bed_to_Toilet\", \"Enter_Home\", \"Leave_Home\", \"Housekeeping\", \"Respirate\"]\n",
    "\n",
    "# Loop through each line of the data\n",
    "for line in data:\n",
    "    # Split the line into its components\n",
    "    components = re.split(\"\\s+\", line.strip())\n",
    "\n",
    "    date = components[0]\n",
    "    time = components[1]\n",
    "    device_id = components[2]\n",
    "    device_status = components[3]\n",
    "    if len(components) > 4:\n",
    "        activity = components[4]\n",
    "        activity_status = components[5]\n",
    "\n",
    "    formatted_date = int(date.replace(\"-\", \"\"))\n",
    "    formatted_time = int(time.replace(\":\", \"\")[:6] + time.replace(\":\", \"\")[7:])\n",
    "\n",
    "    if device_id.startswith(\"M\"):\n",
    "        if device_status.startswith(\"ON\"):\n",
    "            device_status = \"ON\"\n",
    "        elif device_status.startswith(\"OFF\"):\n",
    "            device_status = \"OFF\"\n",
    "\n",
    "    # Append the processed data to the list\n",
    "    if len(components) > 4:\n",
    "        processed_data.append([formatted_date, formatted_time, device_id, device_status, activity, activity_status])\n",
    "    else:\n",
    "        processed_data.append([formatted_date, formatted_time, device_id, device_status, \"\", \"\"])\n",
    "\n",
    "# Write the processed data to a new file\n",
    "with open(\"Processed Data/Aruba_17/pre_processed_data.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Date\",\"Time\", \"Device ID\", \"Status\", \"Activity\", \"Activity Status\"])\n",
    "    for data in processed_data:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Processing Code\n",
    "The original data is saved in a way that the model cannot use. The model needs the data to be numerical. This code will convert the previous file into a csv that the model can be trained on. Saved as processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ID Mapping: {'D001': 0, 'D002': 1, 'D004': 2, 'M001': 3, 'M002': 4, 'M003': 5, 'M004': 6, 'M005': 7, 'M006': 8, 'M007': 9, 'M008': 10, 'M009': 11, 'M010': 12, 'M011': 13, 'M012': 14, 'M013': 15, 'M014': 16, 'M015': 17, 'M016': 18, 'M017': 19, 'M018': 20, 'M019': 21, 'M020': 22, 'M021': 23, 'M022': 24, 'M023': 25, 'M024': 26, 'M025': 27, 'M026': 28, 'M027': 29, 'M028': 30, 'M029': 31, 'M030': 32, 'M031': 33, 'T001': 34, 'T002': 35, 'T003': 36, 'T004': 37, 'T005': 38}\n",
      "Status Mapping: {'16': 0, '16.5': 1, '17': 2, '17.5': 3, '18': 4, '18.5': 5, '19': 6, '19.5': 7, '20': 8, '20.5': 9, '21': 10, '21.5': 11, '22': 12, '22.5': 13, '23': 14, '23.5': 15, '24': 16, '24.5': 17, '25': 18, '25.5': 19, '26': 20, '26.5': 21, '27': 22, '27.5': 23, '28': 24, '28.5': 25, '29': 26, '29.5': 27, '30': 28, '30.5': 29, '31': 30, '31.5': 31, '32': 32, '32.5': 33, '33': 34, '33.5': 35, '34': 36, '34.5': 37, '35': 38, '35.5': 39, '36': 40, '36.5': 41, '37': 42, '37.5': 43, '38': 44, '38.5': 45, '39': 46, '39.5': 47, '40.5': 48, '41.5': 49, '42': 50, '42.5': 51, '43': 52, 'CLOSE': 53, 'OFF': 54, 'ON': 55, 'OPEN': 56}\n",
      "Activity Mapping: {'Bed_to_Toilet': 0, 'Eating': 1, 'Enter_Home': 2, 'Housekeeping': 3, 'Leave_Home': 4, 'Meal_Preparation': 5, 'Relax': 6, 'Respirate': 7, 'Sleeping': 8, 'Wash_Dishes': 9, 'Work': 10, nan: 11}\n",
      "Activity Status Mapping: {'begin': 0, 'end': 1, nan: 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Load the processed data file\n",
    "data = pd.read_csv(\"Processed Data/Aruba_17/pre_processed_data.csv\")\n",
    "\n",
    "# Encode the following columns: Timestamp,Device ID,Status,Activity,Activity Status\n",
    "\n",
    "device_id_encoder = LabelEncoder()\n",
    "status_encoder = LabelEncoder()\n",
    "activity_encoder = LabelEncoder()\n",
    "activity_status_encoder = LabelEncoder()\n",
    "\n",
    "device_id_encoder.fit(data['Device ID'])\n",
    "status_encoder.fit(data['Status'])\n",
    "activity_encoder.fit(data['Activity'])\n",
    "activity_status_encoder.fit(data['Activity Status'])\n",
    "\n",
    "device_id_mapping = dict(zip(device_id_encoder.classes_, device_id_encoder.transform(device_id_encoder.classes_)))\n",
    "status_mapping = dict(zip(status_encoder.classes_, status_encoder.transform(status_encoder.classes_)))\n",
    "activity_mapping = dict(zip(activity_encoder.classes_, activity_encoder.transform(activity_encoder.classes_)))\n",
    "activity_status_mapping = dict(zip(activity_status_encoder.classes_, activity_status_encoder.transform(activity_status_encoder.classes_)))\n",
    "\n",
    "data['Device ID'] = device_id_encoder.transform(data['Device ID'])\n",
    "data['Status'] = status_encoder.transform(data['Status'])\n",
    "data['Activity'] = activity_encoder.transform(data['Activity'])\n",
    "data['Activity Status'] = activity_status_encoder.transform(data['Activity Status'])\n",
    "\n",
    "data.to_csv('Processed Data/Aruba_17/processed_data.csv', index=False)\n",
    "\n",
    "print(\"Device ID Mapping:\", device_id_mapping)\n",
    "print(\"Status Mapping:\", status_mapping)\n",
    "print(\"Activity Mapping:\", activity_mapping)\n",
    "print(\"Activity Status Mapping:\", activity_status_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Post-processing Code\n",
    "This code will inport the prediction data from the model. It will then convert the Label Encoded data back into the original labels. Saved as COMPLETE_PREDICTION.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date          Time  Device ID  Status  Activity  Activity Status\n",
      "0  20101690.0  3.656886e+10       19.0    48.0      12.0              2.0\n",
      "1  20101512.0  3.318584e+10       19.0    48.0      12.0              2.0\n",
      "2  20101472.0  3.691396e+10       17.0    48.0      11.0              2.0\n",
      "3  20101430.0  2.712579e+10       17.0    50.0      12.0              2.0\n",
      "4  20101244.0  3.607466e+10       16.0    50.0      11.0              2.0\n"
     ]
    }
   ],
   "source": [
    "def round_and_inverse_transform(value, mapping, encoder):\n",
    "    max_val = len(mapping) - 1\n",
    "    rounded_val = round(value)\n",
    "    clipped_val = min(max(rounded_val, 0), max_val)\n",
    "    return encoder.inverse_transform([clipped_val])[0]\n",
    "\n",
    "data = pd.read_csv(\"Predictions/Aruba_17_prediction_OLD.txt\")\n",
    "data.columns = ['Date', 'Time', 'Device ID', 'Status', 'Activity', 'Activity Status']\n",
    "print(data.head())\n",
    "\n",
    "data['Device ID'] = data['Device ID'].apply(round_and_inverse_transform, args=(device_id_mapping, device_id_encoder))\n",
    "data['Status'] = data['Status'].apply(round_and_inverse_transform, args=(status_mapping, status_encoder))\n",
    "data['Activity'] = data['Activity'].apply(round_and_inverse_transform, args=(activity_mapping, activity_encoder))\n",
    "data['Activity Status'] = data['Activity Status'].apply(round_and_inverse_transform, args=(activity_status_mapping, activity_status_encoder))\n",
    "\n",
    "# save the data to a new file\n",
    "data.to_csv('Predictions/Aruba_17_completed_prediction_test.txt', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.-1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
