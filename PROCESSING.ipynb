{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing code\n",
    "This code will convert the original data file into a csv for the Aruba dataset. Saved as pre_processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Open the input file for reading\n",
    "with open(\"Raw Data/Aruba_17/data\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    # only read the first 1000 lines\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data = []\n",
    "\n",
    "# Possible activities\n",
    "activities = [\"Meal_Preparation\", \"Relax\", \"Eating\", \"Work\", \"Sleeping\", \"Wash_Dishes\", \"Bed_to_Toilet\", \"Enter_Home\", \"Leave_Home\", \"Housekeeping\", \"Respirate\"]\n",
    "\n",
    "# Loop through each line of the data\n",
    "for line in data:\n",
    "    # Split the line into its components\n",
    "    components = re.split(\"\\s+\", line.strip())\n",
    "\n",
    "    date = components[0]\n",
    "    time = components[1]\n",
    "    device_id = components[2]\n",
    "    device_status = components[3]\n",
    "    if len(components) > 4:\n",
    "        activity = components[4]\n",
    "        activity_status = components[5]\n",
    "\n",
    "    try:\n",
    "        timestamp = datetime.datetime.strptime(f'{date} {time}', '%Y-%m-%d %H:%M:%S.%f')\n",
    "        timestamp = int(timestamp.timestamp())\n",
    "\n",
    "    except ValueError:\n",
    "        timestamp = datetime.datetime.strptime(f'{date} {time}', '%Y-%m-%d %H:%M:%S')\n",
    "        timestamp = int(timestamp.timestamp())\n",
    "\n",
    "    if device_id.startswith(\"M\"):\n",
    "        if device_status.startswith(\"ON\"):\n",
    "            device_status = \"ON\"\n",
    "        elif device_status.startswith(\"OFF\"):\n",
    "            device_status = \"OFF\"\n",
    "\n",
    "    # Append the processed data to the list\n",
    "    if len(components) > 4:\n",
    "        processed_data.append([timestamp, device_id, device_status, activity, activity_status])\n",
    "    else:\n",
    "        processed_data.append([timestamp, device_id, device_status, \"\", \"\"])\n",
    "\n",
    "# Write the processed data to a new file\n",
    "with open(\"Processed Data/Aruba_17/pre_processed_data.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Timestamp\", \"Device ID\", \"Status\", \"Activity\", \"Activity Status\"])\n",
    "    for data in processed_data:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Processing Code\n",
    "The original data is saved in a way that the model cannot use. The model needs the data to be numerical. This code will convert the previous file into a csv that the model can be trained on. Saved as processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Load the processed data file\n",
    "data = pd.read_csv(\"Processed Data/Aruba_17/pre_processed_data.csv\")\n",
    "\n",
    "# Encode the following columns: Timestamp,Device ID,Status,Activity,Activity Status\n",
    "timestamp_encoder = LabelEncoder()\n",
    "device_id_encoder = LabelEncoder()\n",
    "status_encoder = LabelEncoder()\n",
    "activity_encoder = LabelEncoder()\n",
    "activity_status_encoder = LabelEncoder()\n",
    "\n",
    "timestamp_encoder.fit(data['Timestamp'])\n",
    "device_id_encoder.fit(data['Device ID'])\n",
    "status_encoder.fit(data['Status'])\n",
    "activity_encoder.fit(data['Activity'])\n",
    "activity_status_encoder.fit(data['Activity Status'])\n",
    "\n",
    "data['Timestamp'] = timestamp_encoder.transform(data['Timestamp'])\n",
    "data['Device ID'] = device_id_encoder.transform(data['Device ID'])\n",
    "data['Status'] = status_encoder.transform(data['Status'])\n",
    "data['Activity'] = activity_encoder.transform(data['Activity'])\n",
    "data['Activity Status'] = activity_status_encoder.transform(data['Activity Status'])\n",
    "\n",
    "data.to_csv('Processed Data/Aruba_17/processed_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Post-processing Code\n",
    "This code will inport the prediction data from the model. It will then convert the Label Encoded data back into the original labels. Saved as COMPLETE_PREDICTION.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Predictions/Aruba_17_prediction.csv\")\n",
    "# data = pd.read_csv(\"Processed Data/Aruba_17/processed_data.csv\")\n",
    "\n",
    "# use inverse_transform to get the original values\n",
    "\n",
    "data['Timestamp'] = timestamp_encoder.inverse_transform(data['Timestamp'])\n",
    "data['Device ID'] = device_id_encoder.inverse_transform(data['Device ID'])\n",
    "data['Status'] = status_encoder.inverse_transform(data['Status'])\n",
    "data['Activity'] = activity_encoder.inverse_transform(data['Activity'])\n",
    "data['Activity Status'] = activity_status_encoder.inverse_transform(data['Activity Status'])\n",
    "\n",
    "# undo the timestamp code to get the original two columns, date and time, in the following form: 2010-11-04 00:03:50.209589\n",
    "data['Timestamp'] = data['Timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "\n",
    "# split the timestamp column into two columns, date and time\n",
    "data[['Date', 'Time']] = data['Timestamp'].str.split(' ', 1, expand=True)\n",
    "\n",
    "# drop the timestamp column\n",
    "data = data.drop(columns=['Timestamp'])\n",
    "\n",
    "# reorder the columns\n",
    "data = data[['Date', 'Time', 'Device ID', 'Status', 'Activity', 'Activity Status']]\n",
    "\n",
    "# save the data to a new file\n",
    "data.to_csv('Predictions/Aruba_17_completed_prediction.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
