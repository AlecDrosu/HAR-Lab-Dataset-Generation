{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing code\n",
    "This code will convert the original data file into a csv for the Aruba dataset. Saved as pre_processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the input file for reading\n",
    "with open(\"Raw Data/Aruba_17/data\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    # only read the first 1000 lines\n",
    "\n",
    "# Create an empty list to store the processed data\n",
    "processed_data = []\n",
    "\n",
    "# Possible activities\n",
    "activities = [\"Meal_Preparation\", \"Relax\", \"Eating\", \"Work\", \"Sleeping\", \"Wash_Dishes\", \"Bed_to_Toilet\", \"Enter_Home\", \"Leave_Home\", \"Housekeeping\", \"Respirate\"]\n",
    "\n",
    "# Loop through each line of the data\n",
    "for line in data:\n",
    "    # Split the line into its components\n",
    "    components = re.split(\"\\s+\", line.strip())\n",
    "\n",
    "    date = components[0]\n",
    "    time = components[1]\n",
    "    device_id = components[2]\n",
    "    device_status = components[3]\n",
    "    if len(components) > 4:\n",
    "        activity = components[4]\n",
    "        activity_status = components[5]\n",
    "\n",
    "    try:\n",
    "        timestamp = datetime.datetime.strptime(f'{date} {time}', '%Y-%m-%d %H:%M:%S.%f')\n",
    "        timestamp = int(timestamp.timestamp())\n",
    "\n",
    "    except ValueError:\n",
    "        timestamp = datetime.datetime.strptime(f'{date} {time}', '%Y-%m-%d %H:%M:%S')\n",
    "        timestamp = int(timestamp.timestamp())\n",
    "\n",
    "    if device_id.startswith(\"M\"):\n",
    "        if device_status.startswith(\"ON\"):\n",
    "            device_status = \"ON\"\n",
    "        elif device_status.startswith(\"OFF\"):\n",
    "            device_status = \"OFF\"\n",
    "\n",
    "    # Append the processed data to the list\n",
    "    if len(components) > 4:\n",
    "        processed_data.append([timestamp, device_id, device_status, activity, activity_status])\n",
    "    else:\n",
    "        processed_data.append([timestamp, device_id, device_status, \"\", \"\"])\n",
    "\n",
    "# Write the processed data to a new file\n",
    "with open(\"Processed Data/Aruba_17/pre_processed_data.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Timestamp\", \"Device ID\", \"Status\", \"Activity\", \"Activity Status\"])\n",
    "    for data in processed_data:\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Processing Code\n",
    "The original data is saved in a way that the model cannot use. The model needs the data to be numerical. This code will convert the previous file into a csv that the model can be trained on. Saved as processed_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ID Mapping: {'D001': 0, 'D002': 1, 'D004': 2, 'M001': 3, 'M002': 4, 'M003': 5, 'M004': 6, 'M005': 7, 'M006': 8, 'M007': 9, 'M008': 10, 'M009': 11, 'M010': 12, 'M011': 13, 'M012': 14, 'M013': 15, 'M014': 16, 'M015': 17, 'M016': 18, 'M017': 19, 'M018': 20, 'M019': 21, 'M020': 22, 'M021': 23, 'M022': 24, 'M023': 25, 'M024': 26, 'M025': 27, 'M026': 28, 'M027': 29, 'M028': 30, 'M029': 31, 'M030': 32, 'M031': 33, 'T001': 34, 'T002': 35, 'T003': 36, 'T004': 37, 'T005': 38}\n",
      "Status Mapping: {'16': 0, '16.5': 1, '17': 2, '17.5': 3, '18': 4, '18.5': 5, '19': 6, '19.5': 7, '20': 8, '20.5': 9, '21': 10, '21.5': 11, '22': 12, '22.5': 13, '23': 14, '23.5': 15, '24': 16, '24.5': 17, '25': 18, '25.5': 19, '26': 20, '26.5': 21, '27': 22, '27.5': 23, '28': 24, '28.5': 25, '29': 26, '29.5': 27, '30': 28, '30.5': 29, '31': 30, '31.5': 31, '32': 32, '32.5': 33, '33': 34, '33.5': 35, '34': 36, '34.5': 37, '35': 38, '35.5': 39, '36': 40, '36.5': 41, '37': 42, '37.5': 43, '38': 44, '38.5': 45, '39': 46, '39.5': 47, '40.5': 48, '41.5': 49, '42': 50, '42.5': 51, '43': 52, 'CLOSE': 53, 'OFF': 54, 'ON': 55, 'OPEN': 56}\n",
      "Activity Mapping: {'Bed_to_Toilet': 0, 'Eating': 1, 'Enter_Home': 2, 'Housekeeping': 3, 'Leave_Home': 4, 'Meal_Preparation': 5, 'Relax': 6, 'Respirate': 7, 'Sleeping': 8, 'Wash_Dishes': 9, 'Work': 10, nan: 11}\n",
      "Activity Status Mapping: {'begin': 0, 'end': 1, nan: 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Load the processed data file\n",
    "data = pd.read_csv(\"Processed Data/Aruba_17/pre_processed_data.csv\")\n",
    "\n",
    "# Encode the following columns: Timestamp,Device ID,Status,Activity,Activity Status\n",
    "timestamp_encoder = LabelEncoder()\n",
    "device_id_encoder = LabelEncoder()\n",
    "status_encoder = LabelEncoder()\n",
    "activity_encoder = LabelEncoder()\n",
    "activity_status_encoder = LabelEncoder()\n",
    "\n",
    "timestamp_encoder.fit(data['Timestamp'])\n",
    "device_id_encoder.fit(data['Device ID'])\n",
    "status_encoder.fit(data['Status'])\n",
    "activity_encoder.fit(data['Activity'])\n",
    "activity_status_encoder.fit(data['Activity Status'])\n",
    "\n",
    "timestamp_mapping = dict(zip(timestamp_encoder.classes_, timestamp_encoder.transform(timestamp_encoder.classes_)))\n",
    "device_id_mapping = dict(zip(device_id_encoder.classes_, device_id_encoder.transform(device_id_encoder.classes_)))\n",
    "status_mapping = dict(zip(status_encoder.classes_, status_encoder.transform(status_encoder.classes_)))\n",
    "activity_mapping = dict(zip(activity_encoder.classes_, activity_encoder.transform(activity_encoder.classes_)))\n",
    "activity_status_mapping = dict(zip(activity_status_encoder.classes_, activity_status_encoder.transform(activity_status_encoder.classes_)))\n",
    "\n",
    "data['Timestamp'] = timestamp_encoder.transform(data['Timestamp'])\n",
    "data['Device ID'] = device_id_encoder.transform(data['Device ID'])\n",
    "data['Status'] = status_encoder.transform(data['Status'])\n",
    "data['Activity'] = activity_encoder.transform(data['Activity'])\n",
    "data['Activity Status'] = activity_status_encoder.transform(data['Activity Status'])\n",
    "\n",
    "data.to_csv('Processed Data/Aruba_17/processed_data.csv', index=False)\n",
    "\n",
    "print(\"Device ID Mapping:\", device_id_mapping)\n",
    "print(\"Status Mapping:\", status_mapping)\n",
    "print(\"Activity Mapping:\", activity_mapping)\n",
    "print(\"Activity Status Mapping:\", activity_status_mapping)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Post-processing Code\n",
    "This code will inport the prediction data from the model. It will then convert the Label Encoded data back into the original labels. Saved as COMPLETE_PREDICTION.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mPredictions/Aruba_17_prediction.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39m# data = pd.read_csv(\"Processed Data/Aruba_17/processed_data.csv\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39m# use inverse_transform to get the original values\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mTimestamp\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m timestamp_encoder\u001b[39m.\u001b[39;49minverse_transform(data[\u001b[39m'\u001b[39;49m\u001b[39mTimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      7\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mDevice ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m device_id_encoder\u001b[39m.\u001b[39minverse_transform(data[\u001b[39m'\u001b[39m\u001b[39mDevice ID\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m status_encoder\u001b[39m.\u001b[39minverse_transform(data[\u001b[39m'\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_label.py:163\u001b[0m, in \u001b[0;36mLabelEncoder.inverse_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(diff))\n\u001b[0;32m    162\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(y)\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_[y]\n",
      "\u001b[1;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Predictions/Aruba_17_prediction.csv\")\n",
    "# data = pd.read_csv(\"Processed Data/Aruba_17/processed_data.csv\")\n",
    "\n",
    "# use inverse_transform to get the original values\n",
    "\n",
    "data['Timestamp'] = timestamp_encoder.inverse_transform(data['Timestamp'])\n",
    "data['Device ID'] = device_id_encoder.inverse_transform(data['Device ID'])\n",
    "data['Status'] = status_encoder.inverse_transform(data['Status'])\n",
    "data['Activity'] = activity_encoder.inverse_transform(data['Activity'])\n",
    "data['Activity Status'] = activity_status_encoder.inverse_transform(data['Activity Status'])\n",
    "\n",
    "# undo the timestamp code to get the original two columns, date and time, in the following form: 2010-11-04 00:03:50.209589\n",
    "data['Timestamp'] = data['Timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "\n",
    "# split the timestamp column into two columns, date and time\n",
    "data[['Date', 'Time']] = data['Timestamp'].str.split(' ', 1, expand=True)\n",
    "\n",
    "# drop the timestamp column\n",
    "data = data.drop(columns=['Timestamp'])\n",
    "\n",
    "# reorder the columns\n",
    "data = data[['Date', 'Time', 'Device ID', 'Status', 'Activity', 'Activity Status']]\n",
    "\n",
    "# save the data to a new file\n",
    "data.to_csv('Predictions/Aruba_17_completed_prediction.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
