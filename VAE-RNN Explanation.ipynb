{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Lambda, LSTM, RepeatVector, TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the original dataset\n",
    "processed_data = pd.read_csv('Processed Data/Aruba_17/processed_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the maximum number that can be evenly divisible by 32, given the length of the dataset, since the data needs to be evenly divisible by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = len(processed_data) - len(processed_data) % 32\n",
    "processed_data = processed_data.head(3200)\n",
    "\n",
    "# Extract the relevant columns from the dataset\n",
    "timestamp = processed_data['Timestamp'].values\n",
    "device_id = processed_data['Device ID'].values\n",
    "status = processed_data['Status'].values\n",
    "activity = processed_data['Activity'].values\n",
    "activity_status = processed_data['Activity Status'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old Normalization code, not used anymore since it resulted in a bunch of negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.stack((timestamp, device_id, status, activity, activity_status), axis=1)\n",
    "\n",
    "# # Normalize the data using z-score normalization\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Scale the values to be within the range of 0 to 1\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "# X = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Tensorboard to visualize the training process. This is not used in the final version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the log directory for TensorBoard\n",
    "log_dir = \"logs/\"\n",
    "\n",
    "# Create a callback for TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use stack to implement the data. The normalize the original way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for input into the VAE model\n",
    "X = np.stack((timestamp, device_id, status, activity, activity_status), axis=1)\n",
    "\n",
    "# Normalize the data using minMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# print(X.head(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 14 specific activity patterns I wanted to recognize, which is why I chose 14 as the number of clusters. However, this code needs to be studied and modified further. Next we have the batch size, validation split, timesteps, and input dimensions.\n",
    "\n",
    "- #### The input dimensions represent the number of features in the dataset, in this case the number of features is 5.\n",
    "- #### The batch size is chosen based on the following factors:\n",
    "  - i) the amount of memory available for training\n",
    "  - ii) the time it takes to train a single batch\n",
    "  - iii) the variance in the loss function due to the stochastic nature of the gradient updates\n",
    "  - A larger batch size can be faster to train and provide a more stable loss function, but they require more memory and may not generalize as well.\n",
    "  - A smaller batch size may require more time to train and have a noisier loss function, but it can generalize better.\n",
    "  - Current batch size is 32 based on research online. But this will likely be changed in the future.\n",
    "- #### Validation Split:\n",
    "  - The fraction of the dataset used for validation during training. It should be chosen to provide nough validatio ndata to accurately estimate the performace of the model without reducing the amount of data avaialble for training. Current validation split is 0.2, which is typical, and means 20% of the data is used for validation.\n",
    "- #### Timesteps:\n",
    "  - This is the number of previous records considered in the model. The value of timesteps should be chosen based on the time dependence of the data. If the data has long-term dependencies, a larger value of timesteps may be required to capture the dependencies. The current value is 128, but I will likely attempt increasing this value, as some patterns in the data have long term time dependence. Having a value of 128 means the previous 128 records are considered to predict the next record. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use KMeans to cluster sequences into 14 different groups\n",
    "kmeans = KMeans(n_clusters=14, random_state=0)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "timesteps = 128 # number of previous records considered\n",
    "input_dim = X.shape[1] # number of features, there are 5 features in the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code seperates the data into training and testing splits. Afterward the data is padded to ensure it is divisible by the desired shape. This was done because there was a constant issue of the data not being divisible by the batch size, even though the values it was returning were divisible. This code resolves the issue, and reshapes the data into the desired shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, clusters, test_size=validation_split, shuffle=False)\n",
    "\n",
    "# Pad the data to ensure it is divisible by the desired shape\n",
    "remainder_train = X_train.shape[0] % (batch_size * timesteps)\n",
    "if remainder_train > 0:\n",
    "    X_train = np.concatenate([X_train, np.zeros((batch_size * timesteps - remainder_train, input_dim))])\n",
    "    y_train = np.concatenate([y_train, np.zeros((batch_size * timesteps - remainder_train,))])\n",
    "    \n",
    "remainder_val = X_val.shape[0] % (batch_size * timesteps)\n",
    "if remainder_val > 0:\n",
    "    X_val = np.concatenate([X_val, np.zeros((batch_size * timesteps - remainder_val, input_dim))])\n",
    "    y_val = np.concatenate([y_val, np.zeros((batch_size * timesteps - remainder_val,))])\n",
    "\n",
    "# Reshape the datasets to have the correct shape for the model\n",
    "X_train = X_train.reshape((-1, timesteps, input_dim))\n",
    "y_train = y_train.reshape((-1, timesteps))\n",
    "\n",
    "X_val = X_val.reshape((-1, timesteps, input_dim))\n",
    "y_val = y_val.reshape((-1, timesteps))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The laten_dim is the dimension of the latent space in the VAE model. It represents the number of dimensions in which the data can be compressed while preserving most of its original information. A larger latent dimension can provide a more accurate reconstruction of the input data but may require more training data and computational resources.\n",
    "\n",
    "The encoding_dim is the dimension of the hidden state in the encoder part of the VAE-RNN model. It represents the number of dimensions in which the data is compressed before being mapped to the latent space. A larger encoding dimension can provide a more accurate compression of the input data but may also require more computational resources.\n",
    "\n",
    "Typical values if the laten_dim are around 2-4.\n",
    "Typical values of the encoding_dim are around 32-64.\n",
    "\n",
    "The optimal values for these hyperparameters will be determined though evaluation of the model once the validation code is implemented properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "encoding_dim = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder takes input data and maps it to the latent space, which is a lower-dimensioned representation of the input data. \n",
    "\n",
    "The decoder is the secord part of the model that takes the output of the encoder and maps it back to the original input data space. \n",
    "\n",
    "The latent space is a liwer dimensional representation of the input data that is learned by the encoder. The latent space is typically much smaller than the original input data space, which allows the model to compress the input data.\n",
    "\n",
    "##### LSTM\n",
    "An LSTM layer is a type of Recurrent Neural Network (RNN) layer that can remember information over long periods. It is used to process sequential data, such as time-series data, and has a cell state that can store information over time.\n",
    "\n",
    "The LSTM layer in the encoder is used to process the input data and extract relevant features.\n",
    "The two LSTM layers in the encoder have different return_sequence values because the first LSTM layer returns a sequence of outputs for each time step, while the second LSTM layer returns only the last output of the sequence.\n",
    "\n",
    "In the encoder:\n",
    "First LSTM returns a sequence of outputs for each time step, which provides the model with more information about the input data. \n",
    "second LSTM returns only the last output of the sequence, which captures higher-level temporal information.\n",
    "\n",
    "In the decoder:\n",
    "The LSTM layer is used to decode the latent representation back into the original input data space.\n",
    "\n",
    "##### Dense\n",
    "The Dense layer is a fully connected layer that connects every neuron in one layer to every neuron in the next layer. It transforms the input data into a lower-dimensional representation, which is learned by the model.\n",
    "\n",
    "The Dense layer in the decoder is used to reconstruct the original input data from the latent space.\n",
    "\n",
    "##### Reshape\n",
    "the Reshape layer is used to change the shape of the input data from a one-dimensional vector to a three-dimensional tensor. The Reshape layer is used to change the shape of the input data without changing its content. The LSTM layer in the encoder expects a three-dimensional tensor as input, so the Reshape layer is used to change the shape of the input data from a one-dimensional vector to a three-dimensional tensor.\n",
    "\n",
    "##### TimeDistributed\n",
    "This layer applies a layer to each time step of the input sequence independently. This is particularly useful in sequence-to-sequence models, where we want to apply a layer to each time step of the input sequence and obtain a corresponding output sequence.\n",
    "\n",
    "the TimeDistributed layer is used in the Decoder to apply the Dense layer to each time step of the LSTM output sequence. The purpose is to generate a reconstructed sequence that is of the same length as the original input sequence, and where each time step is predicted independently based on the corresponding hidden state of the LSTM layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose of the Sampling and LAMBDA layers\n",
    "\n",
    "The sampling function and the Lambda layer are used for the reparameterization trick, which is a technique used in variational autoencoders (VAEs). VAEs are generative models that learn a low-dimensional representation (latent space) of the input data, which can be used to generate new data that resembles the original data.\n",
    "\n",
    "In a VAE, the encoder maps the input data to a distribution in the latent space, which is usually a multivariate Gaussian distribution with a mean vector and a diagonal covariance matrix. The mean and the log-variance of the Gaussian distribution are outputs of the encoder. The z_mean and z_log_var in your code represent the mean and log-variance of the distribution, respectively.\n",
    "\n",
    "However, the gradient of the stochastic gradient descent (SGD) algorithm cannot be propagated through random nodes like the sampling process. Therefore, we use the reparameterization trick, which allows us to sample from the distribution using a deterministic transformation of a random noise vector.\n",
    "\n",
    "The sampling function takes z_mean and z_log_var as inputs, and returns a sample from the corresponding Gaussian distribution using a random noise vector generated by K.random_normal. The Lambda layer wraps the sampling function, so that it can be used as a Keras layer. The z output of the Lambda layer is the sampled vector in the latent space, which is used as input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==================== ENCODER ====================\n",
    "inputs = Input(batch_shape=(batch_size, timesteps, input_dim), name='encoder_input')\n",
    "x = LSTM(encoding_dim*2, return_sequences=True)(inputs)\n",
    "x = LSTM(encoding_dim, return_sequences=False)(x) \n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "# z_mean is the mean of the latent space\n",
    "# z_log_var is the variance of the latent space\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "# encoder.summary()\n",
    "\n",
    "# ================= LATENT SPACE ==================\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "# ==================== DECODER ====================\n",
    "x = Dense(timesteps * encoding_dim, activation='relu')(latent_inputs)\n",
    "x = Reshape((timesteps, encoding_dim))(x)\n",
    "x = LSTM(encoding_dim, return_sequences=True, input_shape=(timesteps, encoding_dim))(x)\n",
    "x = TimeDistributed(Dense(input_dim))(x)\n",
    "# LSTM layer in the decoder is used to reconstruct the original sequence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the VAE model by combining the encoder and decoder models you previously defined. The VAE model takes in the same input as the encoder model (i.e., inputs) and outputs the same sequence as the decoder model (i.e., outputs).\n",
    "\n",
    "The loss function is composed of two parts: the reconstruction loss and the KL divergence loss. The reconstruction loss measures the difference between the original input and the output of the VAE model, which is the reconstructed input. In this code, binary cross-entropy is used as the reconstruction loss. The KL divergence loss measures the difference between the latent space distribution and a prior distribution, which is usually a normal distribution. The KL divergence loss encourages the VAE to learn a compact representation of the input data. The vae_loss variable is the sum of the reconstruction loss and the KL divergence loss.\n",
    "\n",
    "The loss function of VAE has two parts: the reconstruction loss and the KL divergence loss.\n",
    "The reconstruction loss measures the difference between the original input and the output of the VAE model.\n",
    "Binary cross-entropy is used as the reconstruction loss in the code.\n",
    "The KL divergence loss measures the difference between the latent space distribution and a prior distribution, usually a normal distribution.\n",
    "The KL divergence loss encourages the VAE to learn a compact representation of the input data.\n",
    "The vae_loss variable is the sum of the reconstruction loss and the KL divergence loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the VAE model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "decoder = Model(latent_inputs, x, name='decoder')\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "# Loss function\n",
    "reconstruction_loss = K.mean(binary_crossentropy(K.flatten(inputs), K.flatten(outputs)))\n",
    "reconstruction_loss *= timesteps * input_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.mean(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "# vae_loss = reconstruction_loss + kl_loss\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "# vae.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the VAE model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 100\n",
    "history = vae.fit(X_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[tensorboard_callback])\n",
    "\n",
    "plot_model(vae, to_file='model.png', show_shapes=True)\n",
    "# Use the encoder to generate embeddings for each sequence\n",
    "encoder_model = Model(inputs, z_mean)\n",
    "# print(encoder_model.layers[0].input_shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings for each sequence in the training data using the encoder model. These embeddings capture the most important features of the input sequences and can be used for various downstream tasks, such as clustering, classification, or visualization. The resulting cluster assignments can provide insights into the structure of the data and can be used for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_embedded = encoder_model.predict(X_train, batch_size=batch_size)\n",
    "# Potentially change from the encoder_model to the vae_model, it will be slower but will be more expressive and representative of the data.\n",
    "\n",
    "# Train a classifier on the embeddings\n",
    "y_pred = kmeans.fit_predict(X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a fake dataset using the VAE model\n",
    "n_samples = len(processed_data)\n",
    "\n",
    "noise = np.random.normal(size=(n_samples, timesteps, input_dim))\n",
    "predicted_values = vae.predict(noise, batch_size=batch_size)\n",
    "# reshape predicted values to have the correct shape\n",
    "predicted_values = np.reshape(predicted_values, (n_samples, timesteps, input_dim))\n",
    "\n",
    "# undo the normalization\n",
    "predicted_values = np.reshape(predicted_values, (-1, input_dim))\n",
    "# predicted_values = min_max_scaler.inverse_transform(predicted_values)\n",
    "predicted_values = scaler.inverse_transform(predicted_values)\n",
    "# Round each of the values in the array to the nearest integer\n",
    "predicted_values = np.rint(predicted_values)\n",
    "\n",
    "# Save the prediction data to a new file 'predicted_Data.csv'\n",
    "predicted_data = pd.DataFrame(predicted_values.reshape((-1, input_dim)), columns=['Timestamp', 'Device ID', 'Status', 'Activity', 'Activity Status'])\n",
    "# predicted_data['Cluster'] = y_pred.reshape(-1)\n",
    "# predicted_data.to_csv('Predictions/Aruba_17_prediction.csv', index=False)\n",
    "with open('Predictions/Aruba_17_prediction.txt', 'w') as file:\n",
    "    for _, row in predicted_data.iterrows():\n",
    "        file.write(','.join(map(str, row.values)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss with x and y labels, and a grid\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Validation loss > training loss, underfitting\n",
    "# validation loss > training loss, overfitting, if it decreases and then increases again.\n",
    "# If they both decreease and stabilize at a specific point, it is an optimal fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the model\n",
    "# from keras.utils import plot_model\n",
    "\n",
    "# # Display the layers, number of layers, number of nodes etc\n",
    "# plot_model(vae, to_file='vae.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# # Load the image and display it\n",
    "# img = plt.imread('vae.png')\n",
    "# plt.figure(figsize=(16, 12))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
