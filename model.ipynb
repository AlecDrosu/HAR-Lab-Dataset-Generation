{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data file\n",
    "processed_data = pd.read_csv(\"Processed Data/Aruba_17/processed_data.csv\")\n",
    "# make processed_data only be the first 1000 rows\n",
    "processed_data = processed_data.head(1000)\n",
    "\n",
    "# Create mapping for Status column\n",
    "def map_status(row):\n",
    "    if row['Device ID'][0] == 'M':\n",
    "        status_map = {'ON': 1, 'OFF': 0}\n",
    "        return status_map.get(row['Status'], -1)\n",
    "    elif row['Device ID'][0] == 'T':\n",
    "        return row['Status']\n",
    "    else:\n",
    "        status_map = {'OPEN': 1, 'CLOSE': 0}\n",
    "        return status_map.get(row['Status'], -1)\n",
    "\n",
    "processed_data['Status'] = processed_data.apply(map_status, axis=1)\n",
    "\n",
    "# Create mapping for Device ID column\n",
    "def device_id_to_numeric(device_id):\n",
    "    if device_id.startswith(\"M\"):\n",
    "        return int(\"1\" + device_id[1:])\n",
    "    elif device_id.startswith(\"T\"):\n",
    "        return int(\"2\" + device_id[1:])\n",
    "    elif device_id.startswith(\"D\"):\n",
    "        return int(\"3\" + device_id[1:])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "processed_data['Device ID'] = processed_data['Device ID'].apply(device_id_to_numeric)\n",
    "\n",
    "\n",
    "# Create mapping for Activity column\n",
    "activity_map = {'Meal_Preparation': 0, 'Relax': 1, 'Eating': 2, 'Work': 3, 'Sleeping': 4, 'Wash_Dishes': 5, 'Bed_to_Toilet': 6, 'Enter_Home': 7, 'Leave_Home': 8, 'Housekeeping': 9, 'Respirate': 10}\n",
    "processed_data['Activity'] = processed_data['Activity'].map(activity_map)\n",
    "\n",
    "# Create mapping for Activity Status column\n",
    "activity_status_map = {'begin': 1, 'end': 0}\n",
    "processed_data['Activity Status'] = processed_data['Activity Status'].map(activity_status_map)\n",
    "\n",
    "# Convert the columns to float\n",
    "processed_data['Timestamp'] = processed_data['Timestamp'].astype(float)\n",
    "processed_data['Device ID'] = processed_data['Device ID'].astype(float)\n",
    "processed_data['Status'] = processed_data['Status'].astype(float)\n",
    "processed_data['Activity'] = processed_data['Activity'].astype(float)\n",
    "processed_data['Activity Status'] = processed_data['Activity Status'].astype(float)\n",
    "\n",
    "processed_data = processed_data.fillna(-1)\n",
    "processed_data = processed_data.astype(float)\n",
    "\n",
    "processed_data.to_csv('processed_data_converted.csv', index=False)\n",
    "# print(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 32)           192         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            66          ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            66          ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 324\n",
      "Trainable params: 324\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " z_sampling (InputLayer)     [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                96        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"vae\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 2),          324         ['encoder_input[0][0]']          \n",
      "                                 (None, 2),                                                       \n",
      "                                 (None, 2)]                                                       \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 5)            261         ['encoder[0][2]']                \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 32)           192         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            66          ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            66          ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 2)           0           ['z_log_var[0][0]']              \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.square_3 (TFOpLambda)  (None, 2)            0           ['z_mean[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.cast_7 (TFOpLambda)         (None, 5)            0           ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_3 (TFOpLa  (None, 5)           0           ['decoder[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.subtract_6 (TFOpLambda  (None, 2)           0           ['tf.__operators__.add_6[0][0]', \n",
      " )                                                                'tf.math.square_3[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp_3 (TFOpLambda)     (None, 2)            0           ['z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      " tf.keras.backend.binary_crosse  (None, 5)           0           ['tf.cast_7[0][0]',              \n",
      " ntropy_1 (TFOpLambda)                                            'tf.convert_to_tensor_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.math.subtract_7 (TFOpLambda  (None, 2)           0           ['tf.math.subtract_6[0][0]',     \n",
      " )                                                                'tf.math.exp_3[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_4 (TFOpLam  (None,)             0           ['tf.keras.backend.binary_crossen\n",
      " bda)                                                            tropy_1[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_5 (TFOpLamb  (None,)             0           ['tf.math.subtract_7[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLambda  (None,)             0           ['tf.math.reduce_mean_4[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_5[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TFOpLa  (None,)             0           ['tf.math.multiply_6[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_7[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_5 (TFOpLam  ()                  0           ['tf.__operators__.add_7[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_1 (AddLoss)           ()                   0           ['tf.math.reduce_mean_5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 585\n",
      "Trainable params: 585\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 3.5631 - val_loss: 3.3298\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.1461 - val_loss: 2.9561\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.8471 - val_loss: 2.6137\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2.5262 - val_loss: 2.3334\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.2722 - val_loss: 2.0286\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.9938 - val_loss: 1.8473\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7617 - val_loss: 1.5545\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6030 - val_loss: 1.4646\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4733 - val_loss: 1.3041\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3898 - val_loss: 1.2151\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3063 - val_loss: 1.1448\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2512 - val_loss: 1.1191\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1942 - val_loss: 1.1175\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1803 - val_loss: 1.0340\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1550 - val_loss: 1.0525\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1475 - val_loss: 1.0522\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1275 - val_loss: 1.0542\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1129 - val_loss: 1.0108\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1166 - val_loss: 1.0138\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1106 - val_loss: 1.0090\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1102 - val_loss: 1.0189\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1039 - val_loss: 1.0185\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0869 - val_loss: 1.0139\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0826 - val_loss: 0.9998\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0905 - val_loss: 1.0226\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0945 - val_loss: 1.0315\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0796 - val_loss: 0.9846\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0782 - val_loss: 0.9696\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0816 - val_loss: 0.9978\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0805 - val_loss: 0.9921\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0741 - val_loss: 0.9684\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0745 - val_loss: 1.0004\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0742 - val_loss: 0.9884\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0710 - val_loss: 1.0007\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0730 - val_loss: 0.9903\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0731 - val_loss: 0.9976\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0771 - val_loss: 1.0087\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0709 - val_loss: 0.9830\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0785 - val_loss: 1.0220\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0700 - val_loss: 0.9837\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0731 - val_loss: 1.0163\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0609 - val_loss: 1.0015\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0702 - val_loss: 0.9848\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0696 - val_loss: 0.9987\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 0.9993\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0678 - val_loss: 0.9968\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0625 - val_loss: 0.9917\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0756 - val_loss: 0.9890\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0691 - val_loss: 0.9907\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0604 - val_loss: 0.9730\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0655 - val_loss: 0.9868\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0637 - val_loss: 0.9993\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0770 - val_loss: 1.0223\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0676 - val_loss: 0.9840\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0742 - val_loss: 0.9972\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0638 - val_loss: 1.0030\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0702 - val_loss: 1.0086\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0616 - val_loss: 0.9745\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 1.0571 - val_loss: 0.9912\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0712 - val_loss: 0.9828\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0684 - val_loss: 1.0071\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0645 - val_loss: 0.9899\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0650 - val_loss: 1.0204\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0592 - val_loss: 1.0009\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0656 - val_loss: 0.9835\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0644 - val_loss: 1.0043\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0644 - val_loss: 0.9973\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0700 - val_loss: 0.9966\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0616 - val_loss: 0.9864\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0654 - val_loss: 0.9857\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0614 - val_loss: 0.9838\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0673 - val_loss: 1.0026\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0619 - val_loss: 0.9960\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0578 - val_loss: 1.0150\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0615 - val_loss: 0.9745\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0859 - val_loss: 0.9917\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0719 - val_loss: 1.0034\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0708 - val_loss: 1.0053\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0633 - val_loss: 0.9966\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0699 - val_loss: 0.9907\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0690 - val_loss: 1.0081\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0725 - val_loss: 0.9967\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0644 - val_loss: 0.9785\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0667 - val_loss: 0.9975\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0636 - val_loss: 1.0055\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0641 - val_loss: 0.9893\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0678 - val_loss: 0.9732\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0689 - val_loss: 0.9966\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0696 - val_loss: 1.0004\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0660 - val_loss: 0.9965\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0602 - val_loss: 0.9977\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0653 - val_loss: 0.9985\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0681 - val_loss: 0.9845\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0656 - val_loss: 0.9944\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0707 - val_loss: 0.9785\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0635 - val_loss: 0.9956\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0773 - val_loss: 0.9915\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0774 - val_loss: 0.9965\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0612 - val_loss: 1.0077\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0640 - val_loss: 0.9938\n",
      "32/32 [==============================] - 0s 945us/step\n"
     ]
    }
   ],
   "source": [
    "# newest attempt:\n",
    "\n",
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "\n",
    "\n",
    "# Load the original dataset\n",
    "processed_data = pd.read_csv('processed_data_converted.csv')\n",
    "\n",
    "# Extract the relevant columns from the dataset\n",
    "timestamp = processed_data['Timestamp'].values\n",
    "device_id = processed_data['Device ID'].values\n",
    "status = processed_data['Status'].values\n",
    "activity = processed_data['Activity'].values\n",
    "activity_status = processed_data['Activity Status'].values\n",
    "\n",
    "# Prepare the data for input into the VAE model\n",
    "X = np.stack((timestamp, device_id, status, activity, activity_status), axis=1)\n",
    "\n",
    "# Normalize the data using minMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, X, test_size=validation_split, shuffle=False)\n",
    "X_train = tf.constant(X_train, dtype=tf.float32)\n",
    "X_val = tf.constant(X_val, dtype=tf.float32)\n",
    "\n",
    "latent_dim = 2\n",
    "encoding_dim = 32\n",
    "input_shape = (X_train.shape[1],)\n",
    "\n",
    "# Set the input shape for the VAE model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(encoding_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(encoding_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(input_shape[0], activation='sigmoid')(x)\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= input_shape[0]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "batch_size = 32\n",
    "num_samples = X_train.shape[0]\n",
    "steps_per_epoch = num_samples // batch_size\n",
    "history = vae.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_data=(X_val, y_val), steps_per_epoch=steps_per_epoch)\n",
    "\n",
    "# Generate a fake dataset using the VAE model\n",
    "predicted_values = vae.predict(X)\n",
    "\n",
    "# Save the prediction data to a new file 'predicted_Data.csv'\n",
    "predicted_data = pd.DataFrame(predicted_values, columns=['Timestamp', 'Device ID', 'Status', 'Activity', 'Activity Status'])\n",
    "predicted_data.to_csv('predicted_Data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
