{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data file\n",
    "processed_data = pd.read_csv(\"Processed Data/Aruba_17/processed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ON'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(value)\n\u001b[1;32m---> 12\u001b[0m processed_data[\u001b[39m'\u001b[39m\u001b[39mStatus\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m processed_data[\u001b[39m'\u001b[39;49m\u001b[39mStatus\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(create_status_map)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Create mapping for Device ID column\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdevice_id_to_numeric\u001b[39m(device_id):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1138\u001b[0m             values,\n\u001b[0;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1141\u001b[0m         )\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn [21], line 10\u001b[0m, in \u001b[0;36mcreate_status_map\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m status_map[value[\u001b[39m1\u001b[39m:]]\n\u001b[0;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39;49m(value)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'ON'"
     ]
    }
   ],
   "source": [
    "# Create mapping for Status column\n",
    "def create_status_map(value):\n",
    "    if value[0] == 'M':\n",
    "        status_map = {'ON': 0, 'OFF': 1}\n",
    "        return status_map[value[1:]]\n",
    "    elif value[0] == 'D':\n",
    "        status_map = {'OPEN': 0, 'CLOSE': 1}\n",
    "        return status_map[value[1:]]\n",
    "    else:\n",
    "        return float(value)\n",
    "\n",
    "processed_data['Status'] = processed_data['Status'].apply(create_status_map)\n",
    "\n",
    "# Create mapping for Device ID column\n",
    "def device_id_to_numeric(device_id):\n",
    "    if device_id.startswith(\"M\"):\n",
    "        return int(\"0\" + device_id[1:])\n",
    "    elif device_id.startswith(\"T\"):\n",
    "        return int(\"1\" + device_id[1:])\n",
    "    elif device_id.startswith(\"D\"):\n",
    "        return int(\"2\" + device_id[1:])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "processed_data['Device ID'] = processed_data['Device ID'].apply(device_id_to_numeric)\n",
    "\n",
    "\n",
    "# Create mapping for Activity column\n",
    "activity_map = {'Meal_Preparation': 0, 'Relax': 1, 'Eating': 2, 'Work': 3, 'Sleeping': 4, 'Wash_Dishes': 5, 'Bed_to_Toilet': 6, 'Enter_Home': 7, 'Leave_Home': 8, 'Housekeeping': 9, 'Respirate': 10}\n",
    "processed_data['Activity'] = processed_data['Activity'].map(activity_map)\n",
    "\n",
    "# Create mapping for Activity Status column\n",
    "activity_status_map = {'begin': 0, 'end': 1}\n",
    "processed_data['Activity Status'] = processed_data['Activity Status'].map(activity_status_map)\n",
    "\n",
    "# Convert the columns to float\n",
    "processed_data['Timestamp'] = processed_data['Timestamp'].astype(float)\n",
    "processed_data['Device ID'] = processed_data['Device ID'].astype(float)\n",
    "processed_data['Status'] = processed_data['Status'].astype(float)\n",
    "processed_data['Activity'] = processed_data['Activity'].astype(float)\n",
    "processed_data['Activity Status'] = processed_data['Activity Status'].astype(float)\n",
    "\n",
    "processed_data.to_csv('processed_data_converted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'M003'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Split the data into training and validation sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[39m=\u001b[39m processed_data\u001b[39m.\u001b[39;49miloc[:\u001b[39mint\u001b[39;49m(\u001b[39mlen\u001b[39;49m(processed_data)\u001b[39m*\u001b[39;49m\u001b[39m0.8\u001b[39;49m), :]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m      3\u001b[0m val_data \u001b[39m=\u001b[39m processed_data\u001b[39m.\u001b[39miloc[\u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(processed_data)\u001b[39m*\u001b[39m\u001b[39m0.8\u001b[39m):, :]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Define the inputs for the VAE model\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'M003'"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_data = processed_data.iloc[:int(len(processed_data)*0.8), :].values.astype(np.float32)\n",
    "val_data = processed_data.iloc[int(len(processed_data)*0.8):, :].values.astype(np.float32)\n",
    "\n",
    "# Define the inputs for the VAE model\n",
    "inputs = keras.Input(shape=(train_data.shape[1],))\n",
    "\n",
    "# Define the encoder layer\n",
    "encoder = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "encoder = keras.layers.Dense(32, activation=\"relu\")(encoder)\n",
    "latent = keras.layers.Dense(16, activation=\"relu\")(encoder)\n",
    "\n",
    "# Define the decoder layer\n",
    "decoder = keras.layers.Dense(32, activation=\"relu\")(latent)\n",
    "decoder = keras.layers.Dense(64, activation=\"relu\")(decoder)\n",
    "outputs = keras.layers.Dense(train_data.shape[1], activation=\"sigmoid\")(decoder)\n",
    "\n",
    "# Create the VAE model\n",
    "vae = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the VAE model\n",
    "vae.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "# Fit the VAE model on the training data\n",
    "history = vae.fit(train_data, train_data, epochs=100, batch_size=32, validation_data=(val_data, val_data))\n",
    "\n",
    "# Generate fake datasets\n",
    "fake_datasets = vae.predict(processed_data.values.astype(np.float32))\n",
    "\n",
    "# Write the generated fake datasets to files\n",
    "for i in range(len(fake_datasets)):\n",
    "    fake_dataset = pd.DataFrame(fake_datasets[i], columns=processed_data.columns)\n",
    "    fake_dataset.to_csv(f\"Fake Data/fake_dataset_{i}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e3f0318fa44a63fbd15a81336d0e6b9929111f70e7cf4cecf151c11d26f00aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
